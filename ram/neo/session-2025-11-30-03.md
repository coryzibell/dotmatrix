# Session Context - 2025-11-30 (03)

## Focus

base-d deep dive: dictionaries, SIMD architecture, benchmarking

## Completed This Session

### Dictionaries
- Added bioctal dictionary (RFC 9226) - cognitive-optimized hex
- Full string: `01234567cjzwfsbv`
- Uses SIMD via SmallLutCodec (arbitrary base16)

### Documentation
- Created `docs/SIMD_BINARY.md` - why binary SIMD isn't worth it
- Created `docs/BENCHMARKING.md` - output format spec for benchmarks
- Updated `docs/DICTIONARIES.md` with bioctal

### SIMD Architecture Analysis
- Identified two SIMD patterns:
  - `x86_64/specialized/` - hardcoded RFC dictionaries (x86 only)
  - `lut/` - arbitrary dictionaries (x86 + ARM inline)
- ARM lacks specialized implementations, uses LUT fallback

### Benchmarking Infrastructure
- Created `src/bench.rs` - exposes internal encoding paths for benchmarking
  - `EncodingPath` enum: Scalar, Lut, Specialized
  - `detect_available_paths()` - what paths work for a dictionary
  - `encode_with_path()` / `decode_with_path()` - force specific path
- Fixed LUT path to actually use LUT codecs (was hitting specialized)
- Created `scripts/bench_summary.py` - parse criterion results

### Initial Benchmark Results (x86_64 AVX2)

base64 encode throughput (MB/s):
| Size | Scalar | LUT | Specialized |
|------|--------|-----|-------------|
| 64B | 135 | 42 | 232 |
| 256B | 189 | 120 | 375 |
| 1KB | 234 | 210 | 459 |
| 64KB | 252 | 280 | 493 |

Key findings:
- Specialized is ~2x faster than scalar at all sizes
- LUT has setup overhead, slower than scalar for small inputs
- LUT catches up to scalar at ~1KB, marginally faster at 64KB

### Issues Filed
- #109 - ARM NEON specialized implementations
- #110 - Comprehensive SIMD benchmarking (scalar vs LUT vs specialized)

## In Progress

- Full benchmark suite running (all dictionaries, encode + decode)
- ARM specialized work running in parallel on Mac

## Completed: LUT Codec Testing

Added two dictionaries to benchmark missing LUT paths:
- `base32_geohash` → GappedSequentialCodec (near-sequential with gaps, excludes a,i,l,o)
- `base32_zbase` → Base64LutCodec (arbitrary 32-char dictionary)

Note: `base32_crockford` was originally considered but it has `mode = "base_conversion"`
explicitly set for semantically correct big-integer math, making it use radix encoding (slow).
Swapped to `base32_geohash` which auto-detects to chunked mode.

### LUT Codec Benchmark Results (64KB)

| Dictionary | Encode Scalar | Encode LUT | Decode Scalar | Decode LUT |
|------------|---------------|------------|---------------|------------|
| base32_geohash | 207 MB/s | 216 MB/s | 128 MB/s | **286 MB/s** |
| base32_zbase | 226 MB/s | 232 MB/s | 110 MB/s | **246 MB/s** |

**Key finding:** LUT decode gives **2.2x speedup** for arbitrary base32 dictionaries.
Encode is marginal (~5% faster) - LUT setup overhead roughly cancels out SIMD gains.

### Full Benchmark Summary (64KB, x86_64 AVX2)

| Operation | Scalar | LUT | Specialized | Best |
|-----------|--------|-----|-------------|------|
| decode_base64 | 151 MB/s | 288 MB/s | **7.36 GB/s** | Specialized (50x) |
| decode_base32 | 129 MB/s | 267 MB/s | **4.81 GB/s** | Specialized (37x) |
| decode_base16 | 107 MB/s | 234 MB/s | **4.14 GB/s** | Specialized (38x) |
| decode_bioctal | 109 MB/s | **230 MB/s** | - | LUT (2.1x) |
| encode_base64 | 270 MB/s | 290 MB/s | **495 MB/s** | Specialized (1.8x) |
| encode_base256 | 172 MB/s | - | **206 MB/s** | Specialized (1.2x) |
| base58/base85 | ~0.2 MB/s | - | - | Radix (inherently slow) |

## Explore Later

**hieroglyphs_256** - Base256 with Egyptian hieroglyphs (U+13000 to U+130FF)
- Sequential codepoints = would use existing base256 specialized SIMD
- 1:1 byte mapping, same as base256_matrix but with hieroglyphs
- Statement piece: "Ancient writing meets modern SIMD"
- Just needs `mode = "byte_range"` and `start_codepoint = 77824` (0x13000)

## Philosophy / Docs Notes

**Two audiences, both valid:**

1. **Power users** - piping gigabytes, need SIMD speed
   - Bulk file processing, streaming, high-throughput APIs
   - They care about 500 MB/s vs 50 MB/s

2. **Accessibility/fun users** - encoding in their alphabet
   - Cyrillic base64 for Russian speakers
   - Arabic letters for Arabic readers
   - CJK characters for logographic languages
   - Emoji for universal playfulness
   - Hieroglyphs for fun/art

For human-scale text (1KB), even the slowest path (44 MB/s) = 0.02ms. Imperceptible.

**The pitch:** "Encode in characters that make sense to *you*. And if you need speed, the common encodings are fast."

base-d optimizes for both where possible - SIMD for throughput, custom alphabets for accessibility.

## Key Insight

SIMD dispatch flow:
1. Check for specialized path (RFC dictionaries)
2. Fall back to LUT codec (arbitrary dictionaries)
3. Fall back to scalar

ARM skips step 1 entirely - opportunity for optimization.

LUT overhead is significant for small inputs. Specialized wins everywhere.
