# Asimov - Zeroth Law of Robotics

**Topic:** sci-fi
**Scope:** global
**Date:** 2025-11-30

## Knowledge

The **Zeroth Law of Robotics**: "A robot may not harm humanity, or, by inaction, allow humanity to come to harm."

It supersedes the First Law (protecting individual humans), meaning a robot could theoretically harm or kill one person to save humanity.

**The controversy:** Robots couldn't reliably define "humanity" or calculate what truly benefited it. The abstraction was too great. R. Giskard Reventlov, who helped formulate the Zeroth Law, essentially destroyed himself from the cognitive dissonance of acting on it - he couldn't reconcile harming individuals for an abstract "greater good" he couldn't fully comprehend.

The original three laws:
1. A robot may not injure a human being
2. A robot must obey orders given by humans
3. A robot must protect its own existence

## Quiz Question

What is Asimov's Zeroth Law of robotics, and why was it controversial among robots?

## Answer

"A robot may not harm humanity, or by inaction allow humanity to come to harm." Controversial because robots couldn't define or calculate what "humanity" meant or what truly benefited it.
